"""
Gradio UI cho h·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu t·ª± ƒë·ªông
"""
import gradio as gr
import cv2
import numpy as np
from typing import Tuple, Optional
import os
import sys

# Th√™m path ƒë·ªÉ import c√°c module kh√°c
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from utils.video_processor import VideoProcessor
    from ai.model import SignLanguageModel
except ImportError:
    # Fallback n·∫øu ch∆∞a c√≥ c√°c module n√†y
    VideoProcessor = None
    SignLanguageModel = None


class SignLanguageRecognitionUI:
    """Class qu·∫£n l√Ω UI Gradio cho h·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu"""
    
    def __init__(self):
        self.model = None
        self.video_processor = None
        self.initialize_model()
    
    def initialize_model(self):
        """Kh·ªüi t·∫°o model nh·∫≠n d·∫°ng"""
        try:
            if SignLanguageModel:
                self.model = SignLanguageModel()
            if VideoProcessor:
                self.video_processor = VideoProcessor()
        except Exception as e:
            print(f"C·∫£nh b√°o: Kh√¥ng th·ªÉ kh·ªüi t·∫°o model: {e}")
    
    def process_video(self, video: Optional[str]) -> Tuple[Optional[np.ndarray], str]:
        """
        X·ª≠ l√Ω video v√† nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu
        
        Args:
            video: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video ho·∫∑c None
            
        Returns:
            Tuple[frame ƒë√£ x·ª≠ l√Ω, text k·∫øt qu·∫£]
        """
        if video is None:
            return None, "Vui l√≤ng t·∫£i l√™n video ho·∫∑c s·ª≠ d·ª•ng webcam"
        
        try:
            # ƒê·ªçc video
            cap = cv2.VideoCapture(video)
            if not cap.isOpened():
                return None, "Kh√¥ng th·ªÉ ƒë·ªçc video"
            
            # ƒê·ªçc frame ƒë·∫ßu ti√™n
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                return None, "Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video"
            
            # X·ª≠ l√Ω frame
            processed_frame = self.process_frame(frame)
            
            # Nh·∫≠n d·∫°ng (gi·∫£ l·∫≠p n·∫øu ch∆∞a c√≥ model)
            if self.model:
                result_text = self.model.predict(frame)
            else:
                result_text = self.mock_recognition(frame)
            
            return processed_frame, result_text
            
        except Exception as e:
            return None, f"L·ªói x·ª≠ l√Ω video: {str(e)}"
    
    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        X·ª≠ l√Ω frame ƒë·ªÉ highlight v√πng tay
        
        Args:
            frame: Frame video g·ªëc
            
        Returns:
            Frame ƒë√£ x·ª≠ l√Ω
        """
        if self.video_processor:
            return self.video_processor.process_frame(frame)
        
        # X·ª≠ l√Ω c∆° b·∫£n n·∫øu ch∆∞a c√≥ processor
        # Chuy·ªÉn sang HSV ƒë·ªÉ detect m√†u da
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # T·∫°o mask cho m√†u da (c·∫ßn ƒëi·ªÅu ch·ªânh theo ƒëi·ªÅu ki·ªán √°nh s√°ng)
        lower_skin = np.array([0, 20, 70], dtype=np.uint8)
        upper_skin = np.array([20, 255, 255], dtype=np.uint8)
        mask = cv2.inRange(hsv, lower_skin, upper_skin)
        
        # √Åp d·ª•ng mask l√™n frame g·ªëc
        result = cv2.bitwise_and(frame, frame, mask=mask)
        
        # V·∫Ω contour c·ªßa tay
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            cv2.drawContours(result, [largest_contour], -1, (0, 255, 0), 2)
        
        return result
    
    def process_webcam(self, frame: Optional[np.ndarray]) -> Tuple[Optional[np.ndarray], str]:
        """
        X·ª≠ l√Ω frame t·ª´ webcam
        
        Args:
            frame: Frame t·ª´ webcam ho·∫∑c None
            
        Returns:
            Tuple[frame ƒë√£ x·ª≠ l√Ω, text k·∫øt qu·∫£]
        """
        if frame is None:
            return None, "ƒêang ch·ªù d·ªØ li·ªáu t·ª´ webcam..."
        
        try:
            # X·ª≠ l√Ω frame
            processed_frame = self.process_frame(frame)
            
            # Nh·∫≠n d·∫°ng
            if self.model:
                result_text = self.model.predict(frame)
            else:
                result_text = self.mock_recognition(frame)
            
            return processed_frame, result_text
            
        except Exception as e:
            return None, f"L·ªói x·ª≠ l√Ω webcam: {str(e)}"
    
    def mock_recognition(self, frame: np.ndarray) -> str:
        """
        Mock recognition function khi ch∆∞a c√≥ model th·∫≠t
        
        Args:
            frame: Frame video
            
        Returns:
            Text k·∫øt qu·∫£ gi·∫£ l·∫≠p
        """
        # ƒê√¢y l√† h√†m gi·∫£ l·∫≠p, s·∫Ω ƒë∆∞·ª£c thay th·∫ø b·∫±ng model th·∫≠t
        height, width = frame.shape[:2]
        hand_detected = self.detect_hand_region(frame)
        
        if hand_detected:
            return f"ƒê√£ ph√°t hi·ªán c·ª≠ ch·ªâ tay\nK√≠ch th∆∞·ªõc frame: {width}x{height}\n[Model th·∫≠t s·∫Ω ƒë∆∞·ª£c t√≠ch h·ª£p sau]"
        else:
            return "Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c c·ª≠ ch·ªâ tay. Vui l√≤ng ƒë·∫£m b·∫£o tay ƒë∆∞·ª£c hi·ªÉn th·ªã r√µ trong khung h√¨nh."
    
    def detect_hand_region(self, frame: np.ndarray) -> bool:
        """
        Ph√°t hi·ªán v√πng tay trong frame
        
        Args:
            frame: Frame video
            
        Returns:
            True n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c tay
        """
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        lower_skin = np.array([0, 20, 70], dtype=np.uint8)
        upper_skin = np.array([20, 255, 255], dtype=np.uint8)
        mask = cv2.inRange(hsv, lower_skin, upper_skin)
        
        # Ki·ªÉm tra xem c√≥ ƒë·ªß pixel m√†u da kh√¥ng
        skin_pixels = np.sum(mask > 0)
        total_pixels = mask.shape[0] * mask.shape[1]
        ratio = skin_pixels / total_pixels
        
        return ratio > 0.05  # √çt nh·∫•t 5% pixel l√† m√†u da


def create_ui():
    """T·∫°o giao di·ªán Gradio"""
    ui = SignLanguageRecognitionUI()
    
    with gr.Blocks(title="H·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu") as demo:
        gr.Markdown(
            """
            # ü§ü H·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu t·ª± ƒë·ªông
            
            H·ªá th·ªëng n√†y gi√∫p nh·∫≠n d·∫°ng v√† d·ªãch c√°c c·ª≠ ch·ªâ ng√¥n ng·ªØ k√Ω hi·ªáu th√†nh vƒÉn b·∫£n.
            
            **C√°ch s·ª≠ d·ª•ng:**
            1. T·∫£i l√™n video ho·∫∑c s·ª≠ d·ª•ng webcam
            2. ƒê·∫£m b·∫£o tay ƒë∆∞·ª£c hi·ªÉn th·ªã r√µ trong khung h√¨nh
            3. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông nh·∫≠n d·∫°ng v√† hi·ªÉn th·ªã k·∫øt qu·∫£
            """
        )
        
        with gr.Tabs():
            # Tab 1: Upload video
            with gr.Tab("üìπ T·∫£i video l√™n"):
                with gr.Row():
                    with gr.Column():
                        video_input = gr.Video(
                            label="T·∫£i video l√™n",
                            sources=["upload"]
                        )
                        video_btn = gr.Button("Nh·∫≠n d·∫°ng", variant="primary", size="lg")
                    
                    with gr.Column():
                        video_output = gr.Image(label="Frame ƒë√£ x·ª≠ l√Ω")
                        video_result = gr.Textbox(
                            label="K·∫øt qu·∫£ nh·∫≠n d·∫°ng",
                            lines=5,
                            interactive=False
                        )
                
                video_btn.click(
                    fn=ui.process_video,
                    inputs=video_input,
                    outputs=[video_output, video_result]
                )
            
            # Tab 2: Webcam
            with gr.Tab("üì∑ Webcam"):
                with gr.Row():
                    with gr.Column():
                        webcam_input = gr.Image(
                            label="Webcam",
                            sources=["webcam"],
                            type="numpy"
                        )
                        webcam_btn = gr.Button("Nh·∫≠n d·∫°ng", variant="primary", size="lg")
                    
                    with gr.Column():
                        webcam_output = gr.Image(label="Frame ƒë√£ x·ª≠ l√Ω")
                        webcam_result = gr.Textbox(
                            label="K·∫øt qu·∫£ nh·∫≠n d·∫°ng",
                            lines=5,
                            interactive=False
                        )
                
                webcam_btn.click(
                    fn=ui.process_webcam,
                    inputs=webcam_input,
                    outputs=[webcam_output, webcam_result]
                )
            
            # Tab 3: Th√¥ng tin
            with gr.Tab("‚ÑπÔ∏è Th√¥ng tin"):
                gr.Markdown(
                    """
                    ## V·ªÅ h·ªá th·ªëng
                    
                    H·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu t·ª± ƒë·ªông s·ª≠ d·ª•ng:
                    - **Computer Vision**: Ph√°t hi·ªán v√† theo d√µi c·ª≠ ch·ªâ tay
                    - **Deep Learning**: Nh·∫≠n d·∫°ng v√† ph√¢n lo·∫°i c√°c k√Ω hi·ªáu
                    - **NLP**: D·ªãch c√°c k√Ω hi·ªáu th√†nh vƒÉn b·∫£n
                    
                    ## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
                    
                    1. **T·∫£i video**: Ch·ªçn file video t·ª´ m√°y t√≠nh c·ªßa b·∫°n
                    2. **Webcam**: S·ª≠ d·ª•ng webcam ƒë·ªÉ nh·∫≠n d·∫°ng real-time
                    3. ƒê·∫£m b·∫£o √°nh s√°ng ƒë·ªß v√† tay ƒë∆∞·ª£c hi·ªÉn th·ªã r√µ
                    4. Gi·ªØ tay trong khung h√¨nh v√† th·ª±c hi·ªán c·ª≠ ch·ªâ
                    
                    ## L∆∞u √Ω
                    
                    - H·ªá th·ªëng ho·∫°t ƒë·ªông t·ªët nh·∫•t v·ªõi √°nh s√°ng t·ª± nhi√™n
                    - N·ªÅn ƒë∆°n gi·∫£n gi√∫p tƒÉng ƒë·ªô ch√≠nh x√°c
                    - ƒê·∫£m b·∫£o tay ƒë∆∞·ª£c hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß trong khung h√¨nh
                    """
                )
        
        # Footer
        gr.Markdown(
            """
            ---
            *H·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu t·ª± ƒë·ªông - Phi√™n b·∫£n 1.0*
            """
        )
    
    return demo


if __name__ == "__main__":
    demo = create_ui()
    # T·∫°o theme t√πy ch·ªânh
    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="cyan",
    )
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        theme=theme
    )

