"""
Gradio UI cho h·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu t·ª± ƒë·ªông
T√≠ch h·ª£p v·ªõi SLR API Server
"""
import gradio as gr
import cv2
import numpy as np
import requests
import tempfile
import time
import threading
from typing import Tuple, Optional, List, Dict
from collections import deque
import os
import sys

# Th√™m path ƒë·ªÉ import c√°c module kh√°c
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


# ============== CONFIGURATION ==============
API_BASE_URL = os.getenv("SLR_API_URL", "http://localhost:8000")
API_PREDICT_URL = f"{API_BASE_URL}/api/v1/slr/predict"
API_PREDICT_TOPK_URL = f"{API_BASE_URL}/api/v1/slr/predict/topk"
API_PREDICT_CONTINUOUS_URL = f"{API_BASE_URL}/api/v1/slr/predict/continuous"
API_HEALTH_URL = f"{API_BASE_URL}/api/v1/slr/health"
API_LABELS_URL = f"{API_BASE_URL}/api/v1/slr/labels"

# Real-time settings
BUFFER_SECONDS = 2.0  # S·ªë gi√¢y buffer tr∆∞·ªõc khi g·ª≠i ƒë·ªÉ predict
FPS_TARGET = 15  # Target FPS cho recording


class SignLanguageRecognitionUI:
    """Class qu·∫£n l√Ω UI Gradio cho h·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu"""
    
    def __init__(self):
        self.api_healthy = False
        self.labels: List[str] = []
        self.prediction_history: deque = deque(maxlen=10)
        self.current_sequence: List[str] = []
        
        # Real-time webcam state
        self.is_recording = False
        self.frame_buffer: List[np.ndarray] = []
        self.last_prediction_time = 0
        
        # Check API health
        self.check_api_health()
    
    def check_api_health(self) -> Dict:
        """Ki·ªÉm tra tr·∫°ng th√°i API server"""
        try:
            response = requests.get(API_HEALTH_URL, timeout=5)
            if response.status_code == 200:
                data = response.json()
                self.api_healthy = data.get("model_loaded", False)
                return data
        except Exception as e:
            print(f"API health check failed: {e}")
        
        self.api_healthy = False
        return {"status": "disconnected", "model_loaded": False}
    
    def get_labels(self) -> List[str]:
        """L·∫•y danh s√°ch labels t·ª´ API"""
        try:
            response = requests.get(API_LABELS_URL, timeout=5)
            if response.status_code == 200:
                data = response.json()
                self.labels = data.get("labels", [])
                return self.labels
        except Exception:
            pass
        return []
    
    def predict_video(self, video_path: str, top_k: int = 5) -> Dict:
        """G·ªçi API predict cho video file"""
        try:
            with open(video_path, 'rb') as f:
                files = {"file": ("video.mp4", f, "video/mp4")}
                response = requests.post(
                    f"{API_PREDICT_TOPK_URL}?k={top_k}",
                    files=files,
                    timeout=60
                )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {"success": False, "error": response.text}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def predict_continuous(self, video_path: str, window_seconds: float = 2.0, 
                          stride_seconds: float = 1.0) -> Dict:
        """G·ªçi API predict continuous cho video d√†i"""
        try:
            # Convert to compatible format if needed
            compatible_path = self.ensure_video_compatible(video_path)
            
            with open(compatible_path, 'rb') as f:
                files = {"file": ("video.mp4", f, "video/mp4")}
                params = {
                    "window_seconds": window_seconds,
                    "stride_seconds": stride_seconds,
                    "min_confidence": 0.3
                }
                response = requests.post(
                    API_PREDICT_CONTINUOUS_URL,
                    files=files,
                    params=params,
                    timeout=120
                )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {"success": False, "error": response.text}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def ensure_video_compatible(self, video_path: str) -> str:
        """
        ƒê·∫£m b·∫£o video c√≥ format compatible v·ªõi API
        N·∫øu video kh√¥ng ƒë·ªçc ƒë∆∞·ª£c, convert b·∫±ng OpenCV
        """
        # Th·ª≠ ƒë·ªçc video tr∆∞·ªõc
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            cap.release()
            return video_path  # Tr·∫£ v·ªÅ path g·ªëc, ƒë·ªÉ API x·ª≠ l√Ω l·ªói
        
        # ƒê·ªçc th·ª≠ 1 frame
        ret, _ = cap.read()
        cap.release()
        
        if ret:
            return video_path  # Video ƒë·ªçc ƒë∆∞·ª£c, d√πng tr·ª±c ti·∫øp
        
        # N·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c, th·ª≠ convert (hi·∫øm khi x·∫£y ra)
        return video_path
    
    def predict_from_frames(self, frames: List[np.ndarray]) -> Dict:
        """Convert frames to video v√† predict"""
        if not frames:
            return {"success": False, "error": "No frames"}
        
        # T·∫°o video t·∫°m t·ª´ frames
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            height, width = frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(tmp_path, fourcc, FPS_TARGET, (width, height))
            
            for frame in frames:
                # Chuy·ªÉn t·ª´ RGB sang BGR cho OpenCV
                if len(frame.shape) == 3 and frame.shape[2] == 3:
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                else:
                    frame_bgr = frame
                out.write(frame_bgr)
            
            out.release()
            
            # Predict
            return self.predict_video(tmp_path, top_k=3)
        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    # ============== UI HANDLERS ==============
    
    def process_uploaded_video(self, video: Optional[str], mode: str) -> Tuple[str, str, str]:
        """
        X·ª≠ l√Ω video upload
        
        Returns:
            Tuple[k·∫øt qu·∫£ ch√≠nh, top-k predictions, sequence (n·∫øu continuous)]
        """
        if video is None:
            return "‚ùå Vui l√≤ng t·∫£i l√™n video", "", ""
        
        if not self.api_healthy:
            health = self.check_api_health()
            if not self.api_healthy:
                return f"‚ùå API Server kh√¥ng s·∫µn s√†ng: {health}", "", ""
        
        try:
            if mode == "single":
                # Single prediction
                result = self.predict_video(video, top_k=5)
                
                if result.get("success"):
                    predictions = result.get("predictions", [])
                    
                    # Format main result
                    if predictions:
                        main = predictions[0]
                        main_text = f"üéØ **{main['label']}** (confidence: {main['confidence']*100:.1f}%)"
                    else:
                        main_text = "Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c"
                    
                    # Format top-k
                    topk_text = "\n".join([
                        f"{i+1}. {p['label']} - {p['confidence']*100:.1f}%"
                        for i, p in enumerate(predictions)
                    ])
                    
                    return main_text, topk_text, ""
                else:
                    return f"‚ùå L·ªói: {result.get('error', 'Unknown')}", "", ""
            
            else:
                # Continuous prediction
                result = self.predict_continuous(video, window_seconds=2.0, stride_seconds=0.5)
                
                if result.get("success"):
                    sequence = result.get("sequence", [])
                    sequence_text = result.get("sequence_text", "")
                    segments = result.get("segments", [])
                    
                    main_text = f"üé¨ Nh·∫≠n d·∫°ng ƒë∆∞·ª£c {len(sequence)} k√Ω hi·ªáu"
                    
                    # Format segments
                    segments_text = "\n".join([
                        f"[{s['start_frame']}-{s['end_frame']}] {s['label']} ({s['confidence']*100:.1f}%)"
                        for s in segments[:10]  # Ch·ªâ show 10 segments ƒë·∫ßu
                    ])
                    if len(segments) > 10:
                        segments_text += f"\n... v√† {len(segments)-10} segments kh√°c"
                    
                    return main_text, segments_text, f"üìù Chu·ªói: {sequence_text}"
                else:
                    return f"‚ùå L·ªói: {result.get('error', 'Unknown')}", "", ""
        
        except Exception as e:
            return f"‚ùå L·ªói: {str(e)}", "", ""
    
    def process_webcam_frame(self, frame: Optional[np.ndarray]) -> Tuple[Optional[np.ndarray], str, str]:
        """
        X·ª≠ l√Ω single frame t·ª´ webcam (manual capture)
        """
        if frame is None:
            return None, "üì∑ ƒêang ch·ªù webcam...", ""
        
        # Add frame to buffer
        self.frame_buffer.append(frame.copy())
        
        # N·∫øu ƒë·ªß frames (kho·∫£ng 2 gi√¢y ·ªü 15fps = 30 frames)
        min_frames = int(BUFFER_SECONDS * FPS_TARGET)
        
        if len(self.frame_buffer) >= min_frames:
            # L·∫•y frames v√† predict
            frames_to_predict = list(self.frame_buffer)
            self.frame_buffer.clear()
            
            result = self.predict_from_frames(frames_to_predict)
            
            if result.get("success"):
                predictions = result.get("predictions", [])
                if predictions:
                    main = predictions[0]
                    self.prediction_history.append(main['label'])
                    
                    # Build sequence t·ª´ history (remove duplicates)
                    sequence = []
                    for label in self.prediction_history:
                        if not sequence or sequence[-1] != label:
                            sequence.append(label)
                    self.current_sequence = sequence[-5:]  # Keep last 5
                    
                    result_text = f"üéØ **{main['label']}** ({main['confidence']*100:.1f}%)"
                    sequence_text = " ‚Üí ".join(self.current_sequence) if self.current_sequence else ""
                    
                    return frame, result_text, f"üìù {sequence_text}"
            
            return frame, "‚è≥ ƒêang x·ª≠ l√Ω...", ""
        
        # Hi·ªÉn th·ªã progress
        progress = len(self.frame_buffer) / min_frames * 100
        return frame, f"üìπ Recording: {progress:.0f}% ({len(self.frame_buffer)}/{min_frames} frames)", ""
    
    def start_realtime(self) -> str:
        """B·∫Øt ƒë·∫ßu recording real-time"""
        self.is_recording = True
        self.frame_buffer.clear()
        self.prediction_history.clear()
        self.current_sequence.clear()
        return "üî¥ ƒêang recording... Gi·ªØ tay tr∆∞·ªõc camera"
    
    def stop_realtime(self) -> str:
        """D·ª´ng recording"""
        self.is_recording = False
        return "‚èπÔ∏è ƒê√£ d·ª´ng recording"
    
    def clear_sequence(self) -> str:
        """X√≥a sequence hi·ªán t·∫°i"""
        self.prediction_history.clear()
        self.current_sequence.clear()
        self.frame_buffer.clear()
        return ""
    
    def get_status(self) -> str:
        """L·∫•y tr·∫°ng th√°i h·ªá th·ªëng"""
        health = self.check_api_health()
        
        if health.get("model_loaded"):
            return f"‚úÖ API Server s·∫µn s√†ng | Device: {health.get('device', 'N/A')} | Classes: {health.get('num_classes', 0)}"
        elif health.get("status") == "healthy":
            return "‚ö†Ô∏è API Server ƒëang ch·∫°y nh∆∞ng model ch∆∞a load"
        else:
            return "‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn API Server"


def create_ui():
    """T·∫°o giao di·ªán Gradio"""
    ui = SignLanguageRecognitionUI()
    
    # Custom CSS
    custom_css = """
    .prediction-box {
        font-size: 24px !important;
        font-weight: bold !important;
        text-align: center !important;
        padding: 20px !important;
    }
    .sequence-box {
        font-size: 18px !important;
        color: #2196F3 !important;
    }
    """
    
    with gr.Blocks(
        title="ü§ü Nh·∫≠n d·∫°ng Ng√¥n ng·ªØ K√Ω hi·ªáu",
        css=custom_css,
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="cyan")
    ) as demo:
        
        # Header
        gr.Markdown(
            """
            # ü§ü H·ªá th·ªëng Nh·∫≠n d·∫°ng Ng√¥n ng·ªØ K√Ω hi·ªáu Vi·ªát Nam
            
            S·ª≠ d·ª•ng model **ConvNeXt-Transformer** ƒë·ªÉ nh·∫≠n d·∫°ng 100 k√Ω hi·ªáu ng√¥n ng·ªØ k√Ω hi·ªáu Vi·ªát Nam.
            """
        )
        
        # Status bar
        status_text = gr.Textbox(
            value=ui.get_status(),
            label="Tr·∫°ng th√°i h·ªá th·ªëng",
            interactive=False
        )
        refresh_btn = gr.Button("üîÑ Refresh Status", size="sm")
        refresh_btn.click(fn=ui.get_status, outputs=status_text)
        
        with gr.Tabs():
            # ============== TAB 1: Upload Video ==============
            with gr.Tab("üìπ Upload Video"):
                gr.Markdown("### T·∫£i l√™n video ƒë·ªÉ nh·∫≠n d·∫°ng")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        video_input = gr.Video(
                            label="Video",
                            sources=["upload"]
                        )
                        mode_radio = gr.Radio(
                            choices=["single", "continuous"],
                            value="single",
                            label="Ch·∫ø ƒë·ªô nh·∫≠n d·∫°ng",
                            info="single: 1 k√Ω hi·ªáu | continuous: chu·ªói k√Ω hi·ªáu"
                        )
                        predict_btn = gr.Button("üöÄ Nh·∫≠n d·∫°ng", variant="primary", size="lg")
                    
                    with gr.Column(scale=1):
                        result_main = gr.Markdown(
                            value="K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y",
                            elem_classes=["prediction-box"]
                        )
                        result_topk = gr.Textbox(
                            label="Chi ti·∫øt predictions",
                            lines=6,
                            interactive=False
                        )
                        result_sequence = gr.Textbox(
                            label="Chu·ªói k√Ω hi·ªáu (continuous mode)",
                            lines=2,
                            interactive=False,
                            elem_classes=["sequence-box"]
                        )
                
                predict_btn.click(
                    fn=ui.process_uploaded_video,
                    inputs=[video_input, mode_radio],
                    outputs=[result_main, result_topk, result_sequence]
                )
            
            # ============== TAB 2: Webcam Real-time ==============
            with gr.Tab("üì∑ Webcam Real-time"):
                gr.Markdown(
                    """
                    ### Nh·∫≠n d·∫°ng real-time qua webcam
                    
                    1. B·∫•m **Start** ƒë·ªÉ b·∫Øt ƒë·∫ßu
                    2. Th·ª±c hi·ªán k√Ω hi·ªáu tr∆∞·ªõc camera
                    3. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông nh·∫≠n d·∫°ng m·ªói 2 gi√¢y
                    """
                )
                
                with gr.Row():
                    with gr.Column(scale=1):
                        webcam = gr.Image(
                            label="Webcam",
                            sources=["webcam"],
                            streaming=True,
                            type="numpy"
                        )
                        with gr.Row():
                            start_btn = gr.Button("‚ñ∂Ô∏è Start", variant="primary")
                            stop_btn = gr.Button("‚èπÔ∏è Stop", variant="secondary")
                            clear_btn = gr.Button("üóëÔ∏è Clear", variant="secondary")
                    
                    with gr.Column(scale=1):
                        webcam_status = gr.Textbox(
                            label="Tr·∫°ng th√°i",
                            value="Ch∆∞a b·∫Øt ƒë·∫ßu",
                            interactive=False
                        )
                        webcam_result = gr.Markdown(
                            value="ƒêang ch·ªù...",
                            elem_classes=["prediction-box"]
                        )
                        webcam_sequence = gr.Textbox(
                            label="Chu·ªói ƒë√£ nh·∫≠n d·∫°ng",
                            value="",
                            lines=2,
                            interactive=False,
                            elem_classes=["sequence-box"]
                        )
                
                # Button handlers
                start_btn.click(fn=ui.start_realtime, outputs=webcam_status)
                stop_btn.click(fn=ui.stop_realtime, outputs=webcam_status)
                clear_btn.click(fn=ui.clear_sequence, outputs=webcam_sequence)
                
                # Streaming handler
                webcam.stream(
                    fn=ui.process_webcam_frame,
                    inputs=webcam,
                    outputs=[webcam, webcam_result, webcam_sequence]
                )
            
            # ============== TAB 3: Demo Videos ==============
            with gr.Tab("üé¨ Demo Sentences"):
                gr.Markdown(
                    """
                    ### Demo video c√¢u gh√©p
                    
                    C√°c video demo ƒë∆∞·ª£c t·∫°o t·ª´ vi·ªác gh√©p c√°c k√Ω hi·ªáu ƒë∆°n l·∫ª th√†nh c√¢u c√≥ nghƒ©a.
                    """
                )
                
                with gr.Row():
                    demo_video = gr.Video(label="Demo Video")
                    demo_result = gr.Textbox(
                        label="K·∫øt qu·∫£ nh·∫≠n d·∫°ng continuous",
                        lines=8,
                        interactive=False
                    )
                
                # Example sentences
                gr.Examples(
                    examples=[
                        ["output/sentence_videos/T√¥i_ƒÇn_C√°.mp4"],
                        ["output/sentence_videos/H√¥m-nay_T√¥i_ƒêi_B·ªánh-vi·ªán.mp4"],
                        ["output/sentence_videos/Ch√∫ng-ta_C·∫ßn_Gi√∫p.mp4"],
                    ],
                    inputs=demo_video,
                    label="C√¢u m·∫´u"
                )
            
            # ============== TAB 4: Th√¥ng tin ==============
            with gr.Tab("‚ÑπÔ∏è Th√¥ng tin"):
                gr.Markdown(
                    """
                    ## V·ªÅ h·ªá th·ªëng
                    
                    H·ªá th·ªëng s·ª≠ d·ª•ng ki·∫øn tr√∫c **ConvNeXt-Tiny + Transformer** ƒë·ªÉ nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu Vi·ªát Nam.
                    
                    ### Th√¥ng s·ªë k·ªπ thu·∫≠t
                    - **Model**: ConvNeXt-Tiny (pretrained ImageNet) + Transformer Encoder
                    - **Input**: Video 16 frames @ 224x224
                    - **Output**: 100 classes ng√¥n ng·ªØ k√Ω hi·ªáu
                    
                    ### Ch·∫ø ƒë·ªô nh·∫≠n d·∫°ng
                    
                    | Ch·∫ø ƒë·ªô | M√¥ t·∫£ |
                    |--------|-------|
                    | **Single** | Nh·∫≠n d·∫°ng 1 k√Ω hi·ªáu t·ª´ to√†n b·ªô video |
                    | **Continuous** | Nh·∫≠n d·∫°ng chu·ªói k√Ω hi·ªáu t·ª´ video d√†i |
                    
                    ### API Endpoints
                    
                    ```
                    POST /api/v1/slr/predict       - Nh·∫≠n d·∫°ng ƒë∆°n
                    POST /api/v1/slr/predict/topk  - Top-k predictions
                    POST /api/v1/slr/predict/continuous - Nh·∫≠n d·∫°ng chu·ªói
                    GET  /api/v1/slr/health        - Health check
                    GET  /api/v1/slr/labels        - Danh s√°ch labels
                    ```
                    
                    ### H∆∞·ªõng d·∫´n
                    
                    1. **√Ånh s√°ng**: ƒê·∫£m b·∫£o ƒë·ªß √°nh s√°ng, tr√°nh ng∆∞·ª£c s√°ng
                    2. **V·ªã tr√≠**: ƒê·∫∑t tay trong khung h√¨nh, n·ªÅn ƒë∆°n gi·∫£n
                    3. **T·ªëc ƒë·ªô**: Th·ª±c hi·ªán k√Ω hi·ªáu v·ªõi t·ªëc ƒë·ªô b√¨nh th∆∞·ªùng
                    """
                )
                
                # Show available labels
                with gr.Accordion("üìã Danh s√°ch 100 k√Ω hi·ªáu", open=False):
                    labels_text = gr.Textbox(
                        value="Loading...",
                        lines=10,
                        interactive=False
                    )
                    load_labels_btn = gr.Button("Load Labels")
                    
                    def load_labels():
                        labels = ui.get_labels()
                        if labels:
                            return ", ".join(sorted(labels))
                        return "Kh√¥ng th·ªÉ load labels. Ki·ªÉm tra API server."
                    
                    load_labels_btn.click(fn=load_labels, outputs=labels_text)
        
        # Footer
        gr.Markdown(
            """
            ---
            ü§ü *H·ªá th·ªëng nh·∫≠n d·∫°ng ng√¥n ng·ªØ k√Ω hi·ªáu Vi·ªát Nam - v2.0* | 
            API: `http://localhost:8000/docs`
            """
        )
    
    return demo


if __name__ == "__main__":
    print("üöÄ Starting Sign Language Recognition UI...")
    print(f"üì° API Server: {API_BASE_URL}")
    
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
